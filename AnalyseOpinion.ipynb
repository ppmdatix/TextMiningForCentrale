{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse d’opinion (Polarité de tweet) avec Bayes\n",
    "Par Louis Boivin, Romain Deburghgraeve et Paul Peseux\n",
    "\n",
    "L'objectif de ce Notebbok est d'obtenir un modèle de classification binaire sur des phrases. L'objectif est de dire si une phrase donnée contient une opinion positive ou negative.\n",
    "\n",
    "Il n'y a **pas** d'entre deux. On considère qu'une phrase est soit positive soit négative.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "Petite astuce pour occuper tout l'espace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des packages utiles et utilisés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords \n",
    "import sys\n",
    "from sys import exit \n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix as confusion_matrix\n",
    "from sklearn.metrics import precision_score as precision_score\n",
    "from sklearn.metrics import accuracy_score as accuracy_score\n",
    "from sklearn.metrics import recall_score as recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Petit Exemple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour reprendre l'exemple proposé, on crée à la main un dataset d'entrainement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_tweets = [  (\"I love this car\", \"positive\"),\n",
    "                (\"This view is amazing\", \"positive\"),\n",
    "                (\"I feel great this morning\", \"positive\"),\n",
    "                (\"I am so excited about the concert\", \"positive\"),\n",
    "                (\"He is my best friend\", \"positive\"),\n",
    "                (\"Going well\", \"positive\"),\n",
    "                (\"Thank you\", \"positive\"),\n",
    "                (\"Hope you are doing well\", \"positive\"),\n",
    "                (\"I am very happy\", \"positive\"),\n",
    "                (\"Good for you\", \"positive\"),\n",
    "                (\"It is all good. I know about it and I accept it.\", \"positive\"), (\"This is really good!\", \"positive\"),\n",
    "                (\"Tomorrow is going to be fun.\", \"positive\"),\n",
    "                (\"Smiling all around.\", \"positive\"),\n",
    "                (\"These are great apples today.\", \"positive\"),\n",
    "                (\"How about them apples? Thomas is a happy boy.\", \"positive\"), \n",
    "                (\"Thomas is very zen. He is well−mannered.\", \"positive\")]\n",
    "neg_tweets = [  (\"I do not like this car\", \"negative\"), (\"This view is horrible\", \"negative\"),\n",
    "                (\"I feel tired this morning\", \"negative\"),\n",
    "                (\"I am not looking forward to the concert\", \"negative\"),\n",
    "                (\"He is my enemy\", \"negative\"),\n",
    "                (\"I am a bad boy\", \"negative\"),\n",
    "                (\"This is not good\", \"negative\"),\n",
    "                (\"I am bothered by this\", \"negative\"),\n",
    "                (\"I am not connected with this\", \"negative\"),\n",
    "                (\"Sadistic creep you ass. Die.\", \"negative\"),\n",
    "                (\"All sorts of crazy and scary as hell.\", \"negative\"),\n",
    "                (\"Not his emails, no.\", \"negative\"),\n",
    "                (\"His father is dead. Returned obviously.\", \"negative\"),\n",
    "                (\"He has a bomb.\", \"negative\"),\n",
    "                (\"Too fast to be on foot. We cannot catch them.\", \"negative\")]\n",
    "tweets = []\n",
    "for (words, sentiment) in pos_tweets + neg_tweets:\n",
    "    words_filtered = [e.lower() for e in words.split() if (len(e) >= 3 and not e.lower() in stop_words)] \n",
    "    tweets.append((words_filtered, sentiment))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On se retrouve avec un dataset **tweets** avec les mots filtrés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "On transforme alors cette liste en un training set applicable à un classifieur du type **nltk.NaiveBayesClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mon_get_words_in_tweets(tweets): # from __future__ import print_function\n",
    "    all_words = []\n",
    "    for (words, sentiment) in tweets:\n",
    "        all_words.extend(words) \n",
    "    return all_words\n",
    "def mon_get_word_features(wordlist): \n",
    "    wordlist = nltk.FreqDist(wordlist) \n",
    "    word_features = wordlist.keys() \n",
    "    return word_features\n",
    "\n",
    "def mon_extract_features(document): \n",
    "    document_words = set(document) \n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[\"contains(%s)\" % word] = (word in document_words) \n",
    "    return features\n",
    "word_features = mon_get_word_features(mon_get_words_in_tweets(tweets)) \n",
    "training_set = nltk.classify.apply_features(mon_extract_features, tweets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise le formidable outil _pickle_ pour sauvegrader ce mini-modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_classifier = open(\"tweetposneg.pickle\",\"wb\") \n",
    "pickle.dump(classifier, save_classifier) \n",
    "save_classifier.close()\n",
    "# On doit recharger pour tester d\"autres données de test : on peut le charger par les 3 lignes) : # classifier_f = open(\"naivebayes.pickle\", \"rb\")\n",
    "# classifier = pickle.load(classifier_f)\n",
    "# classifier_f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Grand Exemple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_size = 0.5\n",
    "line_used = 10000\n",
    "path = \"Tweets-folder-Alex/Sentiment-Analysis-Dataset.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du dataset d'entrainement et de test\n",
    "\n",
    "On utilise la fameuse combinaison **pandas/sklearn** afin de générer ces deux datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ppx/.local/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(path, sep=\",\", index_col=\"ItemID\")\n",
    "df = df.head(line_used)\n",
    "\n",
    "train, test = train_test_split(df, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentSource</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8328</th>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>- Threw up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6168</th>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>see yas later mommy :p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5404</th>\n",
       "      <td>1</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>#followfriday @tiggercolman Annoyingly talente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249</th>\n",
       "      <td>1</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>#dontuhateitwhen ppl be lying on you &amp;amp; act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5293</th>\n",
       "      <td>1</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>#flowers BOTD Place colorful gerbera daisies i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentiment SentimentSource  \\\n",
       "ItemID                              \n",
       "8328            0    Sentiment140   \n",
       "6168            0    Sentiment140   \n",
       "5404            1    Sentiment140   \n",
       "6249            1    Sentiment140   \n",
       "5293            1    Sentiment140   \n",
       "\n",
       "                                            SentimentText  \n",
       "ItemID                                                     \n",
       "8328                                          - Threw up   \n",
       "6168                               see yas later mommy :p  \n",
       "5404    #followfriday @tiggercolman Annoyingly talente...  \n",
       "6249    #dontuhateitwhen ppl be lying on you &amp; act...  \n",
       "5293    #flowers BOTD Place colorful gerbera daisies i...  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn0intoneg(x):\n",
    "    if x:\n",
    "        return \"positive\"\n",
    "    else:\n",
    "        return \"negative\"\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette transformation est-elle judicieuse ? \n",
    "\n",
    "Il serait sûrement plus économique de stocker l'information sous True ou False.\n",
    "\n",
    "\n",
    "Cependant c'est une pratique courante en text mining, on s'adapte donc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  \n",
    "def makeTweets(dataFrame):\n",
    "    text = list(df.SentimentText)\n",
    "    sentiment = list(df.Sentiment)\n",
    "    sentiment = [turn0intoneg(s) for s in sentiment]\n",
    "    tweet_sent = [(t,s) for t, s in zip(text, sentiment)]\n",
    "    tweets = []\n",
    "\n",
    "    for (words, sentiment) in tweet_sent:\n",
    "        \n",
    "        words_filtered = [e.lower() for e in words.translate(str.maketrans('', '', string.punctuation)).split() if (len(e) >= 3 and not e.lower() in stop_words)] \n",
    "        \n",
    "        tweets.append((words_filtered, sentiment))\n",
    "    return tweets\n",
    "tweetsTrain = makeTweets(train)\n",
    "tweetsTest = makeTweets(test)\n",
    "\n",
    "textTest = list(test.SentimentText)\n",
    "sentimentTest = list(test.Sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a supprimé les _stopwords_ ainsi que la ponctuation.\n",
    "\n",
    "Ce qui allonge considérablement le préprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = mon_get_word_features(mon_get_words_in_tweets(tweetsTrain)) \n",
    "training_set = nltk.classify.apply_features(mon_extract_features, tweetsTrain) \n",
    "classifier = nltk.NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = []\n",
    "for tweett in textTest:\n",
    "    valued = classifier.classify(mon_extract_features(tweett.split())) \n",
    "    predicted.append(valued)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def turnneginto0(x):\n",
    "    if x==\"positive\":\n",
    "        return 1\n",
    "    elif x==\"negative\":\n",
    "        return 0\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = [turnneginto0(p) for p in predicted]\n",
    "sentimentTest = [turnneginto0(s) for s in sentimentTest]\n",
    "CM = confusion_matrix(sentimentTest, predicted)\n",
    "CM = pd.DataFrame(CM, index = [\"False\", \"True\"], columns=[\"Negative\", \"positive\"])\n",
    "PS = precision_score(sentimentTest, predicted)\n",
    "ACC = accuracy_score(sentimentTest, predicted)\n",
    "REC = recall_score(sentimentTest, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche alors la matrice de confusion, qui permet d'avoir une idée de notre performance sur les données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== RESULTATS ==============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>2848</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>1220</td>\n",
       "      <td>896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Negative  positive\n",
       "False      2848        36\n",
       "True       1220       896"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"=\"*30, \"RESULTATS\", \"=\"*30) \n",
    "CM.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce qui nous donne des métriques :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Précision : 96 %\n",
      "Recall : 42 %\n",
      "Accuracy : 74 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Précision :\", str(int(100 * PS)),  \"%\")\n",
    "print(\"Recall :\", str(int(100 * REC)),  \"%\")\n",
    "print(\"Accuracy :\", str(int(100 * ACC)),  \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le résultat est alors très biaisé, mais donne des performances satisfaisantes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
